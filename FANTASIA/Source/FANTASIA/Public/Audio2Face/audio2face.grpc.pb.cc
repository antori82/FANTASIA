// Generated by the gRPC C++ plugin.
// If you make any local change, they will be lost.
// source: audio2face.proto

#include "audio2face.pb.h"
#include "audio2face.grpc.pb.h"

#include <functional>
#include <grpcpp/support/async_stream.h>
#include <grpcpp/support/async_unary_call.h>
#include <grpcpp/impl/channel_interface.h>
#include <grpcpp/impl/client_unary_call.h>
#include <grpcpp/support/client_callback.h>
#include <grpcpp/support/message_allocator.h>
#include <grpcpp/support/method_handler.h>
#include <grpcpp/impl/rpc_service_method.h>
#include <grpcpp/support/server_callback.h>
#include <grpcpp/impl/codegen/server_callback_handlers.h>
#include <grpcpp/server_context.h>
#include <grpcpp/impl/service_type.h>
#include <grpcpp/support/sync_stream.h>
namespace nvidia {
namespace audio2face {

static const char* Audio2Face_method_names[] = {
  "/nvidia.audio2face.Audio2Face/PushAudio",
  "/nvidia.audio2face.Audio2Face/PushAudioStream",
};

std::unique_ptr< Audio2Face::Stub> Audio2Face::NewStub(const std::shared_ptr< ::grpc::ChannelInterface>& channel, const ::grpc::StubOptions& options) {
  (void)options;
  std::unique_ptr< Audio2Face::Stub> stub(new Audio2Face::Stub(channel, options));
  return stub;
}

Audio2Face::Stub::Stub(const std::shared_ptr< ::grpc::ChannelInterface>& channel, const ::grpc::StubOptions& options)
  : channel_(channel), rpcmethod_PushAudio_(Audio2Face_method_names[0], options.suffix_for_stats(),::grpc::internal::RpcMethod::NORMAL_RPC, channel)
  , rpcmethod_PushAudioStream_(Audio2Face_method_names[1], options.suffix_for_stats(),::grpc::internal::RpcMethod::CLIENT_STREAMING, channel)
  {}

::grpc::Status Audio2Face::Stub::PushAudio(::grpc::ClientContext* context, const ::nvidia::audio2face::PushAudioRequest& request, ::nvidia::audio2face::PushAudioResponse* response) {
  return ::grpc::internal::BlockingUnaryCall< ::nvidia::audio2face::PushAudioRequest, ::nvidia::audio2face::PushAudioResponse, ::grpc::protobuf::MessageLite, ::grpc::protobuf::MessageLite>(channel_.get(), rpcmethod_PushAudio_, context, request, response);
}

void Audio2Face::Stub::async::PushAudio(::grpc::ClientContext* context, const ::nvidia::audio2face::PushAudioRequest* request, ::nvidia::audio2face::PushAudioResponse* response, std::function<void(::grpc::Status)> f) {
  ::grpc::internal::CallbackUnaryCall< ::nvidia::audio2face::PushAudioRequest, ::nvidia::audio2face::PushAudioResponse, ::grpc::protobuf::MessageLite, ::grpc::protobuf::MessageLite>(stub_->channel_.get(), stub_->rpcmethod_PushAudio_, context, request, response, std::move(f));
}

void Audio2Face::Stub::async::PushAudio(::grpc::ClientContext* context, const ::nvidia::audio2face::PushAudioRequest* request, ::nvidia::audio2face::PushAudioResponse* response, ::grpc::ClientUnaryReactor* reactor) {
  ::grpc::internal::ClientCallbackUnaryFactory::Create< ::grpc::protobuf::MessageLite, ::grpc::protobuf::MessageLite>(stub_->channel_.get(), stub_->rpcmethod_PushAudio_, context, request, response, reactor);
}

::grpc::ClientAsyncResponseReader< ::nvidia::audio2face::PushAudioResponse>* Audio2Face::Stub::PrepareAsyncPushAudioRaw(::grpc::ClientContext* context, const ::nvidia::audio2face::PushAudioRequest& request, ::grpc::CompletionQueue* cq) {
  return ::grpc::internal::ClientAsyncResponseReaderHelper::Create< ::nvidia::audio2face::PushAudioResponse, ::nvidia::audio2face::PushAudioRequest, ::grpc::protobuf::MessageLite, ::grpc::protobuf::MessageLite>(channel_.get(), cq, rpcmethod_PushAudio_, context, request);
}

::grpc::ClientAsyncResponseReader< ::nvidia::audio2face::PushAudioResponse>* Audio2Face::Stub::AsyncPushAudioRaw(::grpc::ClientContext* context, const ::nvidia::audio2face::PushAudioRequest& request, ::grpc::CompletionQueue* cq) {
  auto* result =
    this->PrepareAsyncPushAudioRaw(context, request, cq);
  result->StartCall();
  return result;
}

::grpc::ClientWriter< ::nvidia::audio2face::PushAudioStreamRequest>* Audio2Face::Stub::PushAudioStreamRaw(::grpc::ClientContext* context, ::nvidia::audio2face::PushAudioStreamResponse* response) {
  return ::grpc::internal::ClientWriterFactory< ::nvidia::audio2face::PushAudioStreamRequest>::Create(channel_.get(), rpcmethod_PushAudioStream_, context, response);
}

void Audio2Face::Stub::async::PushAudioStream(::grpc::ClientContext* context, ::nvidia::audio2face::PushAudioStreamResponse* response, ::grpc::ClientWriteReactor< ::nvidia::audio2face::PushAudioStreamRequest>* reactor) {
  ::grpc::internal::ClientCallbackWriterFactory< ::nvidia::audio2face::PushAudioStreamRequest>::Create(stub_->channel_.get(), stub_->rpcmethod_PushAudioStream_, context, response, reactor);
}

::grpc::ClientAsyncWriter< ::nvidia::audio2face::PushAudioStreamRequest>* Audio2Face::Stub::AsyncPushAudioStreamRaw(::grpc::ClientContext* context, ::nvidia::audio2face::PushAudioStreamResponse* response, ::grpc::CompletionQueue* cq, void* tag) {
  return ::grpc::internal::ClientAsyncWriterFactory< ::nvidia::audio2face::PushAudioStreamRequest>::Create(channel_.get(), cq, rpcmethod_PushAudioStream_, context, response, true, tag);
}

::grpc::ClientAsyncWriter< ::nvidia::audio2face::PushAudioStreamRequest>* Audio2Face::Stub::PrepareAsyncPushAudioStreamRaw(::grpc::ClientContext* context, ::nvidia::audio2face::PushAudioStreamResponse* response, ::grpc::CompletionQueue* cq) {
  return ::grpc::internal::ClientAsyncWriterFactory< ::nvidia::audio2face::PushAudioStreamRequest>::Create(channel_.get(), cq, rpcmethod_PushAudioStream_, context, response, false, nullptr);
}

Audio2Face::Service::Service() {
  AddMethod(new ::grpc::internal::RpcServiceMethod(
      Audio2Face_method_names[0],
      ::grpc::internal::RpcMethod::NORMAL_RPC,
      new ::grpc::internal::RpcMethodHandler< Audio2Face::Service, ::nvidia::audio2face::PushAudioRequest, ::nvidia::audio2face::PushAudioResponse, ::grpc::protobuf::MessageLite, ::grpc::protobuf::MessageLite>(
          [](Audio2Face::Service* service,
             ::grpc::ServerContext* ctx,
             const ::nvidia::audio2face::PushAudioRequest* req,
             ::nvidia::audio2face::PushAudioResponse* resp) {
               return service->PushAudio(ctx, req, resp);
             }, this)));
  AddMethod(new ::grpc::internal::RpcServiceMethod(
      Audio2Face_method_names[1],
      ::grpc::internal::RpcMethod::CLIENT_STREAMING,
      new ::grpc::internal::ClientStreamingHandler< Audio2Face::Service, ::nvidia::audio2face::PushAudioStreamRequest, ::nvidia::audio2face::PushAudioStreamResponse>(
          [](Audio2Face::Service* service,
             ::grpc::ServerContext* ctx,
             ::grpc::ServerReader<::nvidia::audio2face::PushAudioStreamRequest>* reader,
             ::nvidia::audio2face::PushAudioStreamResponse* resp) {
               return service->PushAudioStream(ctx, reader, resp);
             }, this)));
}

Audio2Face::Service::~Service() {
}

::grpc::Status Audio2Face::Service::PushAudio(::grpc::ServerContext* context, const ::nvidia::audio2face::PushAudioRequest* request, ::nvidia::audio2face::PushAudioResponse* response) {
  (void) context;
  (void) request;
  (void) response;
  return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
}

::grpc::Status Audio2Face::Service::PushAudioStream(::grpc::ServerContext* context, ::grpc::ServerReader< ::nvidia::audio2face::PushAudioStreamRequest>* reader, ::nvidia::audio2face::PushAudioStreamResponse* response) {
  (void) context;
  (void) reader;
  (void) response;
  return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
}


}  // namespace nvidia
}  // namespace audio2face

